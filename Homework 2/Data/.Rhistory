}
author_names
x_train = cbind(author_names,x_train)
x_train
head(x_train)
x_train[1:5,1:5]
file_names = rownames(x_train)
author_names = vector(mode="character",length = length(file_names))
for (i in 1:length(file_names)){
temp_name = strsplit(file_names[i],'/') # Split the file name by the /
author_names[i] = temp_name[[1]][2] # Author name is the always the 2nd element
}
author_names
x_train = cbind(author_names,x_train)
author_dirs = Sys.glob('../data/ReutersC50/C50train/*')
author_dirs = author_dirs[1:2]
file_list = NULL
labels = NULL
for(author in author_dirs) {
author_name = substring(author, first=29)
files_to_add = Sys.glob(paste0(author, '/*.txt'))
file_list = append(file_list, files_to_add)
labels = append(labels, rep(author_name, length(files_to_add)))
}
all_docs = lapply(file_list, readerPlain)
names(all_docs) = file_list
names(all_docs) = sub('.txt', '', names(all_docs))
my_corpus = Corpus(VectorSource(all_docs))
names(my_corpus) = file_list
my_corpus = tm_map(my_corpus, content_transformer(tolower)) # make everything lowercase
my_corpus = tm_map(my_corpus, content_transformer(removeNumbers)) # remove numbers
my_corpus = tm_map(my_corpus, content_transformer(removePunctuation)) # remove punctuation
my_corpus = tm_map(my_corpus, content_transformer(stripWhitespace)) ## remove excess white-space
my_corpus = tm_map(my_corpus, content_transformer(removeWords), stopwords("SMART"))
DTM = DocumentTermMatrix(my_corpus)
DTM # some basic summary statistics
class(DTM)  # a special kind of sparse matrix format
inspect(DTM[1:10,1:20])
DTM = removeSparseTerms(DTM, 0.975)
DTM
X = as.matrix(DTM)
AP_train = X[1:45,]
AC_train = X[51:95,]
smooth_count = 1/nrow(X)
AP_train[1:10,]
w_AP = colSums(AP_train + smooth_count)
w_ap
w_AP
w_AP = w_AP/sum(w_AP)
w_AP
sum(w_AP)
author_names
authors_dedup = unique(author_names)
authors_dedup
names(x_train)
colnames(x_train)
length(authors_dedup)
x_train.columns
length(colnames(x_train))
w_train = matrix(,nrow=length(authors_dedup),ncol = length(colnames(x_train)), colnames = colnames(x_train),rownames = rownames(x_train))
w_train = matrix(,nrow=length(authors_dedup),ncol = length(colnames(x_train)))
colnames(w_train) = colnames(x_train)
rownames(w_train) = rownames(x_train)
typeof(authors_dedup)
type(authors_dedup)
rownames(w_train) = authors_dedup
w_train[1:5][1:5]
rownames(w_train)
colnames(w_train)
colnames(w_train) = colnames(x_train)[2:length(colnames(x_train))]
w_train = matrix(,nrow=length(authors_dedup),ncol = length(colnames(x_train)-1))
w_train = matrix(,nrow=length(authors_dedup),ncol = length(colnames(x_train))-1)
colnames(w_train) = colnames(x_train)[2:length(colnames(x_train))]
colnames(w_train)
colnames(x_train)[1:5]
x_train = as.matrix(DTM_authors)
file_names = rownames(x_train)
author_names = vector(mode="character",length = length(file_names))
for (i in 1:length(file_names)){
temp_name = strsplit(file_names[i],'/') # Split the file name by the /
author_names[i] = temp_name[[1]][2] # Author name is the always the 2nd element
}
x_train = cbind(author_names,x_train)
smooth_count = 1/nrow(x_train)
authors_dedup = unique(author_names)
w_train = matrix(,nrow=length(authors_dedup),ncol = length(colnames(x_train))-1)
colnames(w_train) = colnames(x_train)[2:length(colnames(x_train))]
rownames(w_train) = authors_dedup
colnames(w_train)
w_train[2,]
for(name in authors_dedup){
x_temp = x_train[x_train['author_names'] == name]
w_temp = colsums(x_temp + smooth_count)
w_temp = w_temp/sum(w_temp)
w_train[name,] = w_temp
}
for(name in authors_dedup){
x_temp = x_train[x_train['author_names'] == name]
w_temp = colSums(x_temp + smooth_count)
w_temp = w_temp/sum(w_temp)
w_train[name,] = w_temp
}
x_train['author_names'] == name
name
x_train['author_names']
colnames(x_train)
colnames(x_train)[1:5]
x_train$author_names == name
x_train[,'author_names'] == name
which(x_train[,'author_names'] == name)
x_train = cbind(author_names,x_train)
smooth_count = 1/nrow(x_train)
authors_dedup = unique(author_names)
w_train = matrix(,nrow=length(authors_dedup),ncol = length(colnames(x_train))-1)
colnames(w_train) = colnames(x_train)[2:length(colnames(x_train))]
rownames(w_train) = authors_dedup
x_train = as.matrix(DTM_authors)
file_names = rownames(x_train)
author_names = vector(mode="character",length = length(file_names))
for (i in 1:length(file_names)){
temp_name = strsplit(file_names[i],'/') # Split the file name by the /
author_names[i] = temp_name[[1]][2] # Author name is the always the 2nd element
}
x_train = cbind(author_names,x_train)
smooth_count = 1/nrow(x_train)
colnames(x_train)[1:5]
authors_dedup = unique(author_names)
w_train = matrix(,nrow=length(authors_dedup),ncol = length(colnames(x_train))-1)
colnames(w_train) = colnames(x_train)[2:length(colnames(x_train))]
rownames(w_train) = authors_dedup
for(name in authors_dedup){
x_temp = which(x_train[,'author_names'] == name)
w_temp = colSums(x_temp + smooth_count)
w_temp = w_temp/sum(w_temp)
w_train[name,] = w_temp
}
x_temp
x_temp = x_train[x_train[,'author_names'] == name]
x_temp
x_train[,'author_names'] == name
x_train[x_train[,'author_names'] == name]
for(name in authors_dedup){
x_temp = x_train[which(author_names == name),]
w_temp = colSums(x_temp + smooth_count)
w_temp = w_temp/sum(w_temp)
w_train[name,] = w_temp
}
for(name in authors_dedup){
x_temp = x_train[which(author_names == name),2:length(colnames(x_train))]
w_temp = colSums(x_temp + smooth_count)
w_temp = w_temp/sum(w_temp)
w_train[name,] = w_temp
}
x_temp
x_temp[1:5][1:5]
colnames(x_temp)[1:5]
w_AP = colSums(AP_train + smooth_count)
q_AP
w_AP
AP_train
x_temp
AP_train
x_temp
smooth_count = 1/nrow(X)
w_AP = colSums(AP_train + smooth_count)
smooth_count = 1/nrow(x_train)
w_temp = colSums(x_temp + smooth_count)
typeof(AP_train)
typeof(x_temp)
typeof(X)
for(name in authors_dedup){
x_temp = as.matrix(x_train[which(author_names == name),2:length(colnames(x_train))])
w_temp = colSums(x_temp + smooth_count)
w_temp = w_temp/sum(w_temp)
w_train[name,] = w_temp
}
x_train = as.numeric(x_train)
rownames(x_train)
x_train
x_train = as.matrix(DTM_authors)
file_names = rownames(x_train)
author_names = vector(mode="character",length = length(file_names))
for (i in 1:length(file_names)){
temp_name = strsplit(file_names[i],'/') # Split the file name by the /
author_names[i] = temp_name[[1]][2] # Author name is the always the 2nd element
}
typeof(x_train)
rownames(x_train)
rownames(x_train) = author_names
smooth_count = 1/nrow(x_train)
authors_dedup = unique(author_names)
w_train = matrix(,nrow=length(authors_dedup),ncol = length(colnames(x_train)))
colnames(w_train) = colnames(x_train)
rownames(w_train) = authors_dedup
for(name in authors_dedup){
x_temp = x_train[which(rownames(x_train) == name),]
w_temp = colSums(x_temp + smooth_count)
w_temp = w_temp/sum(w_temp)
w_train[name,] = w_temp
}
w_train[1:5][1:5]
w_train
x_train['AaronPressman',1:5]
x_train[1:5,1:5]
rownames(x_train)[1:15]
w_AP = colSums(AP_train + smooth_count)
w_AP = w_AP/sum(w_AP)
w_AC = colSums(AC_train + smooth_count)
w_AC = w_AC/sum(w_AC)
x_test = X[49,]
x_test
head(sort(x_test, decreasing=TRUE), 25)
sum(x_test*log(w_AP))
sum(x_test*log(w_AC))
w_AP
log(w_AP)
x_test*log(w_AP)
sum(x_test*log(w_AP))
rm(list=ls())
library(tm)
readerPlain = function(fname){
readPlain(elem=list(content=readLines(fname)),
id=fname, language='en')
}
file_list = Sys.glob('../data/ReutersC50/C50train/*/*.txt')
authors = lapply(file_list, readerPlain)
names(authors) = file_list
names(authors) = substring(names(authors),first=28) #gets rid of the file path
names(authors) = sub('.txt', '', names(authors))
my_documents = Corpus(VectorSource(authors))
names(my_documents) = names(authors)
my_documents = tm_map(my_documents, content_transformer(tolower))
my_documents = tm_map(my_documents, content_transformer(removeNumbers))
my_documents = tm_map(my_documents, content_transformer(removePunctuation))
my_documents = tm_map(my_documents, content_transformer(stripWhitespace))
my_documents = tm_map(my_documents, content_transformer(removeWords), stopwords("en"))
DTM_authors = DocumentTermMatrix(my_documents)
DTM_authors = removeSparseTerms(DTM_authors, 0.99)
x_train = as.matrix(DTM_authors)
file_names = rownames(x_train)
author_names = vector(mode="character",length = length(file_names))
for (i in 1:length(file_names)){
temp_name = strsplit(file_names[i],'/') # Split the file name by the /
author_names[i] = temp_name[[1]][2] # Author name is the always the 2nd element
}
rownames(x_train) = author_names # not ideal due to repeated row names, but keeps the matrix as type double
smooth_count = 1/nrow(x_train)
authors_dedup = unique(author_names)
w_train = matrix(,nrow=length(authors_dedup),ncol = length(colnames(x_train)))
colnames(w_train) = colnames(x_train)
rownames(w_train) = authors_dedup
for(name in authors_dedup){
x_temp = x_train[which(rownames(x_train) == name),]
w_temp = colSums(x_temp + smooth_count)
w_temp = w_temp/sum(w_temp)
w_train[name,] = w_temp
}
file_list_test = Sys.glob('../data/ReutersC50/C50test/*/*.txt')
authors_test = lapply(file_list_test, readerPlain)
names(authors_test) = file_list_test
names(authors_test) = substring(names(authors_test),first=27) #gets rid of the file path
names(authors_test) = sub('.txt', '', names(authors_test))
test_docs = Corpus(VectorSource(authors_test))
names(test_docs) = names(authors_test)
test_docs = tm_map(test_docs, content_transformer(tolower))
test_docs = tm_map(test_docs, content_transformer(removePunctuation))
test_docs = tm_map(test_docs, content_transformer(removeNumbers))
test_docs = tm_map(test_docs, content_transformer(stripWhitespace))
test_docs = tm_map(test_docs, content_transformer(removeWords), stopwords("en"))
DTM_test = DocumentTermMatrix(test_docs)
DTM_test = removeSparseTerms(DTM_test, 0.99)
x_test = as.matrix(DTM_test)
file_names = rownames(x_test)
author_names = vector(mode="character",length = length(file_names))
for (i in 1:2500){
temp_name = strsplit(file_names[i],'/') # Split the file name by the /
author_names[i] = temp_name[[1]][2] # Author name is the always the 2nd element
}
rownames(x_test) = author_names
names_train = colnames(x_train)
names_test = colnames(x_test)
missing_words = which(!(names_test %in% names_train))
missing_words
names_test[3237]
names_train == 'voiced'
names_train[names_train == 'voiced']
which(names_train == 'voiced')
names_test[3236]
which(names_train == 'voice')
library(SnowballC)
install.packages("SnowballC")
my_documents = tm_map(my_documents, stemDocument)
install.packages('SnowballC', https://cran.cnr.Berkeley.edu/mirrors/cran')
install.packages('SnowballC', http://cran.cnr.Berkeley.edu/mirrors/cran')
install.packages('SnowballC', 'https://cran.revolutionanalytics.com/')
install.packages('SnowballC', repo = 'https://cran.revolutionanalytics.com/')
install.packages('SnowballC', repo =  'https://cran.cnr.Berkeley.edu/mirrors/cran')
library(SnowballC)
install.packages('SnowballC', repo =  'https://cran.cnr.Berkeley.edu/')
library(RTools)
install.packages("RTools")
library(RTools)
?cbind
c(0*10)
c(0)*10
zeros = c(0*10)
zeros
zeros = c(0)*10
zeros
zeros = list(c(0)*10)
zeros
?list
list(rep(0,5))
as.list(rep(0,5))
list(rep(0,5))
rep(0,5)
missing_words
length(names_train)
nrow(x_train)
ncol(x_train)
missing_words = which(!(names_test %in% names_train))
for(i in missing_words){
word = names_test[i]
x_train = cbind(x_train,rep(0,nrow(x_train)))
colnames(x_train)[ncol(x_train)] = word
}
ncol(x_train)
length(missing)
nrow(missing)
length(missing_words)
3723-3325
word
x_train = as.matrix(DTM_authors)
nrow(x_train)
ncol(x_train)
names_train = colnames(x_train)
names_test = colnames(x_test)
missing_words = which(!(names_test %in% names_train))
for(i in missing_words){
word = names_test[i]
x_train$word = rep(0,nrow(x_train))
colnames(x_train)[ncol(x_train)] = word
}
x_train = as.matrix(DTM_authors)
x_test = as.matrix(DTM_test)
names_train = colnames(x_train)
names_test = colnames(x_test)
missing_words = which(!(names_test %in% names_train))
for(i in missing_words){
word = names_test[i]
x_train = cbind(x_train,rep(0,nrow(x_train)))
colnames(x_train)[ncol(x_train)] = word
}
ncol(x_train)
length(autors_dedup)
length(authors_dedup)
w_train[1:5,]
scores = matrix(,nrow=nrow(x_test, ncol = length(authors_dedup)))
scores = matrix(nrow=nrow(x_test, ncol = length(authors_dedup)))
length(authors_dedup)
scores = matrix(nrow=nrow(x_test), ncol = length(authors_dedup))
colnames(scores) = authors_dedup
for(i in nrow(score)){
for(author in authors_dedup){
scores[i,author] = sum(x_test[i,]*log(w_train[author,]))
}
}
for(i in nrow(scores)){
for(author in authors_dedup){
scores[i,author] = sum(x_test[i,]*log(w_train[author,]))
}
}
warnings()
names_train = colnames(x_train)
names_test = colnames(x_test)
missing_words = which(!(names_test %in% names_train))
for(i in missing_words){
word = names_test[i]
x_train = cbind(x_train,rep(0,nrow(x_train)))
colnames(x_train)[ncol(x_train)] = word
}
extra_words = which(!(names_train %in% names_test))
for(i in extra_words){
word = names_train[i]
x_test = cbind(x_test,rep(0,nrow(x_test)))
colnames(x_test)[ncol(x_test)] = word
}
rm(list = ls())
library(tm)
readerPlain = function(fname){
readPlain(elem=list(content=readLines(fname)),
id=fname, language='en')
}
file_list = Sys.glob('../data/ReutersC50/C50train/*/*.txt')
authors = lapply(file_list, readerPlain)
file_list_test = Sys.glob('../data/ReutersC50/C50test/*/*.txt')
authors_test = lapply(file_list_test, readerPlain)
names(authors) = file_list
names(authors) = substring(names(authors),first=28) #gets rid of the file path
names(authors) = sub('.txt', '', names(authors))
names(authors_test) = file_list_test
names(authors_test) = substring(names(authors_test),first=27) #gets rid of the file path
names(authors_test) = sub('.txt', '', names(authors_test))
my_documents = Corpus(VectorSource(authors))
names(my_documents) = names(authors)
test_docs = Corpus(VectorSource(authors_test))
names(test_docs) = names(authors_test)
my_documents = tm_map(my_documents, content_transformer(tolower))
my_documents = tm_map(my_documents, content_transformer(removeNumbers))
my_documents = tm_map(my_documents, content_transformer(removePunctuation))
my_documents = tm_map(my_documents, content_transformer(stripWhitespace))
my_documents = tm_map(my_documents, content_transformer(removeWords), stopwords("en"))
my_documents = tm_map(my_documents, stemDocument)
test_docs = tm_map(test_docs, content_transformer(tolower))
test_docs = tm_map(test_docs, content_transformer(removeNumbers))
test_docs = tm_map(test_docs, content_transformer(removePunctuation))
test_docs = tm_map(test_docs, content_transformer(stripWhitespace))
test_docs = tm_map(test_docs, content_transformer(removeWords), stopwords("en"))
DTM_authors = DocumentTermMatrix(my_documents)
DTM_authors = removeSparseTerms(DTM_authors, 0.99)
DTM_test = DocumentTermMatrix(test_docs)
DTM_test = removeSparseTerms(DTM_test, 0.99)
x_train = as.matrix(DTM_authors)
x_test = as.matrix(DTM_test)
names_train = colnames(x_train)
names_test = colnames(x_test)
missing_words = which(!(names_test %in% names_train))
for(i in missing_words){
word = names_test[i]
x_train = cbind(x_train,rep(0,nrow(x_train)))
colnames(x_train)[ncol(x_train)] = word
}
extra_words = which(!(names_train %in% names_test))
for(i in extra_words){
word = names_train[i]
x_test = cbind(x_test,rep(0,nrow(x_test)))
colnames(x_test)[ncol(x_test)] = word
}
file_names = rownames(x_train)
author_names = vector(mode="character",length = length(file_names))
for (i in 1:length(file_names)){
temp_name = strsplit(file_names[i],'/') # Split the file name by the /
author_names[i] = temp_name[[1]][2] # Author name is the always the 2nd element
}
test_names = rownames(x_test)
author_test = vector(mode="character",length = length(test_names))
for (i in 1:length(test_names)){
temp_name = strsplit(test_names[i],'/') # Split the file name by the /
author_test[i] = temp_name[[1]][2] # Author name is the always the 2nd element
}
rownames(x_train) = author_names
rownames(x_test) = author_test
smooth_count = 1/nrow(x_train)
authors_dedup = unique(author_names)
w_train = matrix(,nrow=length(authors_dedup),ncol = length(colnames(x_train)))
colnames(w_train) = colnames(x_train)
rownames(w_train) = authors_dedup
for(name in authors_dedup){
x_temp = x_train[which(rownames(x_train) == name),]
w_temp = colSums(x_temp + smooth_count)
w_temp = w_temp/sum(w_temp)
w_train[name,] = w_temp
}
scores = matrix(nrow=nrow(x_test), ncol = length(authors_dedup))
colnames(scores) = authors_dedup
for(i in nrow(scores)){
for(author in authors_dedup){
scores[i,author] = sum(x_test[i,]*log(w_train[author,])) #do we need to add factors to test as well?
}
}
scores[1:5][1:5]
scores
log(w_train[author,])
x_test[i,]
x_test[i,]*log(w_train[author,])
sum(x_test[i,]*log(w_train[author,]))
scores[i,author]
scores[,author]
scores = matrix(nrow=nrow(x_test), ncol = length(authors_dedup))
colnames(scores) = authors_dedup
for(i in 1:nrow(scores)){
for(author in authors_dedup){
scores[i,author] = sum(x_test[i,]*log(w_train[author,])) #do we need to add factors to test as well?
}
}
scores
colnames(scores)[which.max(scores[1,])]
scores[1,]
which.max(scores[1,])
predictions = vector(mode = 'character', length = nrow(scores))
for(i in 1:nrow(scores)){
predictions[i] = colnames(scores)[which.max(scores[i,])]
}
predictions
rownames(x_test_
rownames(x_test)
correct = 0
for(i in 1:nrow(predictions)){
if(predictions[i] == rownames(x_test)[i]){
correct = correct +1
}
}
length(predictions)
for(i in 1:length(predictions)){
if(predictions[i] == rownames(x_test)[i]){
correct = correct +1
}
}
print (paste("Percent correct is",correct/nrow(predictions)))
correct
print (paste("Percent correct is",1.0*correct/nrow(predictions)))
print (paste("Percent correct is",1.0*correct/length(predictions)))
